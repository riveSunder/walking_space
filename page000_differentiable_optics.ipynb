{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fece05f6",
   "metadata": {},
   "source": [
    "# Differentiable Physics \n",
    "\n",
    "<h1> Demos:</h1>\n",
    "\n",
    "* <h2>Neural networks can be very dumb sometimes (inspired by <a hrerf=\"http://physicsbaseddeeplearning.com/intro-teaser.html\">Physics Based Deep Learning</a> book)</h2>\n",
    "\n",
    "* <h2>Differentiable optics models: design</h2>\n",
    "\n",
    "* <h2>Differentiable optics models: inverse problems</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from autograd import numpy as anp\n",
    "from autograd import grad\n",
    "\n",
    "import skimage\n",
    "import skimage.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.asm_prop import save_as_gif, run_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c69615",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def y_parabola(mode=0, batch_size=128, stretch=1.):\n",
    "    \n",
    "    x = np.random.rand(batch_size, 1) * stretch\n",
    "    \n",
    "    if mode == 0:\n",
    "        y = np.sign(np.random.randn(batch_size))[:, np.newaxis] * np.sqrt(x)\n",
    "        \n",
    "    elif mode == 1:\n",
    "        y = -1.0 * np.sqrt(x)\n",
    "        \n",
    "    elif mode == 2:\n",
    "        y = np.sqrt(x)\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "def forward_nn(x, layers, biases):\n",
    "    \n",
    "    #activation = lambda x: x * (x > 0) + x * 0.1 * (x < 0)\n",
    "    #activation = lambda x: x**2\n",
    "    activation = lambda x: anp.sin(x**2)\n",
    "    #activation = lambda x: anp.tanh(x)\n",
    "    \n",
    "    for layer, bias in zip(layers, biases):\n",
    "        \n",
    "        x = activation(anp.matmul(x, layer)) + bias\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "def forward_nn_loss(x, y_target, layers, biases):\n",
    "        \n",
    "    prediction = forward_nn(x, layers, biases)\n",
    "    \n",
    "    loss = anp.mean(anp.abs(y_target - prediction)**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "    \n",
    "def get_layers(dim_x=1, dim_h=32, dim_y=1, number_h=1):\n",
    "    \n",
    "    layers = []\n",
    "    biases = []\n",
    "    \n",
    "    layers.append(30 / (dim_x * dim_h) * np.random.randn(dim_x, dim_h))\n",
    "    biases.append(np.random.randn(dim_h))\n",
    "    \n",
    "\n",
    "    for ii in range(number_h):\n",
    "        layers.append(30 / (dim_h**2) * np.random.randn(dim_h, dim_h))\n",
    "        biases.append(np.random.randn(dim_h))\n",
    "\n",
    "    layers.append(30 / (dim_h * dim_y) * np.random.randn(dim_h, dim_y))\n",
    "    biases.append(np.random.randn(dim_y))\n",
    "    \n",
    "    return layers, biases\n",
    "    \n",
    "\n",
    "get_nn_grad = grad(forward_nn_loss, argnum=(2,3))\n",
    "\n",
    "\n",
    "x, y = y_parabola(batch_size = 2048)\n",
    "\n",
    "max_steps = 2500\n",
    "lr = 3e-4\n",
    "\n",
    "layers, biases = get_layers()\n",
    "\n",
    "val_x, val_y = y_parabola(batch_size = 128)\n",
    "\n",
    "pred_y = forward_nn(val_x, layers, biases)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(val_x, val_y)\n",
    "plt.scatter(val_x, pred_y)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for ii in range(max_steps):\n",
    "    \n",
    "\n",
    "    if ii % (max_steps // 10) == 0:\n",
    "        \n",
    "        loss = forward_nn_loss(x, y, layers, biases)\n",
    "        \n",
    "        print(f\"loss at step {ii} = {loss:.4}\")\n",
    "    \n",
    "    grad_layers, grad_biases = get_nn_grad(x, y, layers, biases)\n",
    "    \n",
    "    for params, grads in zip(layers, grad_layers):\n",
    "        params -=  lr * grads\n",
    "        \n",
    "    for params, grads in zip(biases, grad_biases):\n",
    "        params -=  lr * grads\n",
    "        \n",
    "\n",
    "val_x, val_y = y_parabola(batch_size = 128, stretch=3)\n",
    "\n",
    "pred_y = forward_nn(val_x, layers, biases)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(val_x, val_y)\n",
    "plt.scatter(val_x, pred_y)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18dc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_dp_loss(x, layers, biases):\n",
    "        \n",
    "    prediction = forward_nn(x, layers, biases)\n",
    "    \n",
    "    loss = anp.mean(anp.abs(x - prediction**2)**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "get_dp_grad = grad(forward_dp_loss, argnum=(1,2))\n",
    "\n",
    "layers, biases = get_layers()\n",
    "\n",
    "val_x, val_y = y_parabola(batch_size = 128)\n",
    "\n",
    "pred_y = forward_nn(val_x, layers, biases)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(val_x, val_y)\n",
    "plt.scatter(val_x, pred_y)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for ii in range(max_steps):\n",
    "    \n",
    "\n",
    "    if ii % (max_steps // 10) == 0:\n",
    "        \n",
    "        loss = forward_dp_loss(x, layers, biases)\n",
    "        \n",
    "        print(f\"loss at step {ii} = {loss:.4}\")\n",
    "    \n",
    "    grad_layers, grad_biases = get_dp_grad(x, layers, biases)\n",
    "    \n",
    "    for params, grads in zip(layers, grad_layers):\n",
    "        params -=  lr * grads\n",
    "        \n",
    "    for params, grads in zip(biases, grad_biases):\n",
    "        params -=  lr * grads\n",
    "        \n",
    "\n",
    "val_x, val_y = y_parabola(batch_size = 128, stretch=3)\n",
    "\n",
    "pred_y = forward_nn(val_x, layers, biases)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(val_x, val_y)\n",
    "plt.scatter(val_x, pred_y)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = input(\"Enter an image url (please):\")\n",
    "\n",
    "image_ext = os.path.splitext(image_url)[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./assets\"):\n",
    "    os.system(f\"wget {image_url} -O ./assets/temp{image_ext}\")\n",
    "else:\n",
    "    os.mkdir(\"./assets\")\n",
    "    os.system(f\"wget {image_url} -O ./assets/temp{image_ext}\")\n",
    "\n",
    "my_image = sio.imread(\"./assets/temp.png\")\n",
    "\n",
    "if len(my_image.shape) > 2:\n",
    "    my_image = my_image.mean(axis=-1)\n",
    "    \n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(my_image, cmap=\"plasma\")\n",
    "plt.show()\n",
    "\n",
    "os.system(\"rm ./assets/*gif\")\n",
    "images, losses, tgt_img = run_train(my_image)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses, lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c900bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_gif(images, filename=\"temp_0.gif\")\n",
    "sio.imsave(\"assets/tgt_0.png\", tgt_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51856d9",
   "metadata": {},
   "source": [
    "# Optimization Animation\n",
    "<img src=\"assets/temp_0.gif\" width=40%>\n",
    "\n",
    "# Target Image\n",
    "<img src=\"assets/tgt_0.png\" width=40%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae741ea",
   "metadata": {},
   "source": [
    "## Optimization Animation\n",
    "<img src=\"assets/temp1.gif\" width=40%>\n",
    "\n",
    "## Target Image\n",
    "<img src=\"assets/tgt.png\" width=40%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import skimage\n",
    "import skimage.io as sio\n",
    "import skimage.transform\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def asm_prop(wavefront, length=32.e-3, wavelength=550.e-9, distance=10.e-3):\n",
    "        \n",
    "    if len(wavefront.shape) == 2:\n",
    "        dim_x, dim_y = wavefront.shape\n",
    "    elif len(wavefront.shape) == 3:\n",
    "        number_samples, dim_x, dim_y = wavefront.shape\n",
    "    else:\n",
    "        print(\"only 2D wavefronts or array of 2D wavefronts supported\")\n",
    "\n",
    "    assert dim_x == dim_y, \"wavefront should be square\"\n",
    "    px = length / dim_x\n",
    "\n",
    "    l2 = (1/wavelength)**2\n",
    "    \n",
    "    fx = np.linspace(-1/(2*px), 1/(2*px) - 1/(dim_x*px), dim_x)\n",
    "    fxx, fyy = np.meshgrid(fx,fx)\n",
    "\n",
    "    q = l2 - fxx**2 - fyy**2\n",
    "    q[q<0] = 0.0\n",
    "\n",
    "    h = np.fft.fftshift(np.exp(1.j * 2 * np.pi * distance * np.sqrt(q)))\n",
    "    \n",
    "    fd_wavefront = np.fft.fft2(np.fft.fftshift(wavefront)) \n",
    "    if len(wavefront.shape) == 3:\n",
    "        fd_new_wavefront = h[np.newaxis,:,:] * fd_wavefront\n",
    "        new_wavefront=np.fft.ifftshift(np.fft.ifft2(fd_new_wavefront))[:,:dim_x,:dim_x]\n",
    "    else:\n",
    "        fd_new_wavefront = h * fd_wavefront\n",
    "        new_wavefront = np.fft.ifftshift(np.fft.ifft2(fd_new_wavefront))[:dim_x,:dim_x]\n",
    "\n",
    "\n",
    "    return new_wavefront\n",
    "\n",
    "def onn_layer(wavefront, phase_objects, d=100.e-3):\n",
    "\n",
    "    for ii in range(len(phase_objects)):\n",
    "        wavefront = asm_prop(wavefront * phase_objects[ii], distance=d)\n",
    "\n",
    "    return wavefront\n",
    "\n",
    "def get_loss(wavefront, y_tgt, phase_objects, d=100.e-3):\n",
    "\n",
    "    img = np.abs(onn_layer(wavefront, phase_objects, d=d))**2\n",
    "    mse_loss = np.mean( (img - y_tgt)**2 + np.abs(img-y_tgt) )\n",
    "\n",
    "    return mse_loss\n",
    "\n",
    "get_grad = grad(get_loss, argnum=2)\n",
    "\n",
    "def save_as_gif(np_array, filename=\"my_gif.gif\", my_cmap=None):\n",
    "    \n",
    "    assert (len(np_array.shape) == 3), \"expected n by h by w array\"\n",
    "    \n",
    "    if my_cmap == None:\n",
    "        my_cmap = plt.get_cmap(\"magma\")\n",
    "        \n",
    "    dim_x, dim_y = np_array.shape[-2], np_array.shape[-1]\n",
    "    \n",
    "    im = Image.fromarray((my_cmap(np_array[0])*255).astype(\"uint8\"), \"RGBA\")\n",
    "\n",
    "    im.save(f\"assets/{filename}\", save_all=True, duration=3*np_array.shape[0], loop=0, \\\n",
    "            append_images=[Image.fromarray((my_cmap(img)*255).astype(\"uint8\"), \"RGBA\") for img in np_array[1:]])\n",
    "\n",
    "def run_train(tgt_img, zero_pad=True):\n",
    "\n",
    "    dim = 128\n",
    "    side_length = 32.e-3\n",
    "    aperture = 8.e-3\n",
    "    wavelength = 550.e-9\n",
    "    k0 = 2*np.pi / wavelength\n",
    "    dist = 50.e-3\n",
    "\n",
    "    if zero_pad:\n",
    "        tgt_img = np.pad(tgt_img, (tgt_img.shape[0], tgt_img.shape[1]))\n",
    "    # resize target image\n",
    "    tgt_img = skimage.transform.resize(tgt_img, (dim, dim))\n",
    "    \n",
    "    px = side_length / dim\n",
    "\n",
    "    x = np.linspace(-side_length/2, side_length/2-px, dim)\n",
    "\n",
    "    xx, yy = np.meshgrid(x,x)\n",
    "    rr = np.sqrt(xx**2 + yy**2)\n",
    "\n",
    "    wavefront = np.zeros((dim,dim)) * np.exp(1.j*k0*0.0)\n",
    "    wavefront[rr <= aperture] = 1.0\n",
    "\n",
    "    #tgt_img = sio.imread(\"./smiley.png\")[:,:,0]\n",
    "    \n",
    "    y_tgt = 1.0 * tgt_img / np.max(tgt_img)\n",
    "\n",
    "    lr = 1e-3\n",
    "    phase_objects = [np.exp(1.j * np.zeros((128,128)) ) \\\n",
    "            for aa in range(32)]\n",
    "    losses = []\n",
    "\n",
    "    training_arrays = []\n",
    "    smooth_slope = 0.0\n",
    "    \n",
    "    for step in range(1024):\n",
    "\n",
    "\n",
    "        my_grad = get_grad(wavefront, y_tgt, phase_objects, d=dist)\n",
    "\n",
    "        for params, grads in zip(phase_objects, my_grad):\n",
    "            params -=  lr * np.exp( -1.j * np.angle(grads))\n",
    "\n",
    "        loss = get_loss(wavefront, y_tgt, phase_objects,d=dist)\n",
    "        losses.append(loss)\n",
    "        img = np.abs(onn_layer(wavefront, phase_objects))**2\n",
    "        \n",
    "        if step % 16 == 0:\n",
    "            print(\"loss at step {} = {:.2e}, lr={:.3e}\".format(step, loss, lr))\n",
    "        \n",
    "        training_arrays.append(img/2.0)\n",
    "        \n",
    "        if len(losses) > 1:\n",
    "            smooth_slope = 0.99 * smooth_slope + 0.01 * (losses[-2] - losses[-1])\n",
    "        \n",
    "        if smooth_slope < 0.0:\n",
    "            print(\"stopping training\")\n",
    "            break\n",
    "    \n",
    "    return np.array(training_arrays), losses, tgt_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
